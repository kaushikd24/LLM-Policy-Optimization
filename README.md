# ðŸ§  DPO & GRPO: Advanced Policy Optimization for Language Models

Welcome to my DPO & GRPO project, a comprehensive framework for optimizing language models using Direct Preference Optimization (DPO) and Group Relative Policy Optimization (GRPO), from Deepseek. This project leverages Hugging Face Transformers and PEFT (LoRA) to provide efficient and scalable solutions for preference learning and policy optimization.

---

### Overview

This repository contains two main components:

1. **Direct Preference Optimization (DPO)**: A method for training language models directly from preference pairs using a classification-style loss, improving sample quality and alignment in tasks like summarization, dialogue, and sentiment control.

2. **Group Relative Policy Optimization (GRPO)**: An extension of PPO that handles more complex preference structures, particularly suited for tasks like instruction tuning and mathematical reasoning, and also reduces training resources.

---

### Project Structure

```
dpo_grpo_rlhf/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ prompts.json
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ base_gpt2/
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ dpo_config.yaml
â”‚   â””â”€â”€ grpo_config.yaml
â”‚
â”œâ”€â”€ dpo/
â”‚   â”œâ”€â”€ train_dpo.py
â”‚   â”œâ”€â”€ dpo_trainer.py
â”‚   â”œâ”€â”€ dataset_utils.py
â”‚   â”œâ”€â”€ eval.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ grpo/
â”‚   â”œâ”€â”€ train_grpo.py
â”‚   â”œâ”€â”€ grpo_trainer.py
â”‚   â”œâ”€â”€ dataset_utils.py
â”‚   â”œâ”€â”€ eval.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_model.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### Getting Started

To get started with either DPO or GRPO, ensure you have the necessary dependencies installed:

```bash
pip install -r requirements.txt
```

### Running DPO

Configure your settings in `configs/dpo_config.yaml` and run:

```bash
python dpo/train_dpo.py
```

### Running GRPO

Configure your settings in `configs/grpo_config.yaml` and run:

```bash
python grpo/train_grpo.py
```

---

### Learn More

- **DPO**: [Direct Preference Optimization](https://arxiv.org/abs/2305.18290)
- **GRPO**: [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)

---

### License

This project is licensed under the MIT License.

---

### Acknowledgements

- DPO: Based on the original Stanford DPO paper by Rafailov et al. (2023)
- GRPO: Based on the original DeepSeekMath Reasoning paper by the DeepSeek team.
- HuggingFace team and PEFT for making adapters dead simple

